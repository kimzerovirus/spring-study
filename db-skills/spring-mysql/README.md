## 웹의 기본 아키텍처

웹이 복잡해짐에 따라 분리됨

- 웹서버

- 웹어플리케이션서버

why? 관심사의 분리 / 관측가능한 시스템(범위를 좁히므로 장애가 나면 어디인지 파악 쉬워짐) / 효율적인 리소스 사용 

but 관리할것이 많아짐



## 왜 데이터베이스가 병목일까?

- 스케일 업 : 서버 성능 상승
- 스케일 아웃:  서버의 대수를 증가

|                      | 스케일 업                   | 스케일 아웃                      |
| -------------------- | --------------------------- | -------------------------------- |
| **유지보수 및 관리** | 쉬움                        | 여러 노드에 적절히 부하분산 필요 |
| **확장성**           | 제약이 있음                 | 스케일 업에 비해 자유로움        |
| **장애복구**         | 서버가 1대, 다운타임이 있음 | 장애 탄력성이 있음               |

만약 데이터베이스를 스케일 아웃하게 된다면, 데이터라는 상태를 관리해야 하기 때문에 데이터의 일관성이 깨질 수 있는 위험이 있다. 따라서 서버보다 스케일 아웃을 하기 위한 비용이 훨씬 많이 필요할 것이다.(독립적인 데이터 끼리 파티셔닝 등?)

따라서 현대의 서버 아키텍처는 상태관리를 데이터베이스에 위임하고, 서버는 상태관리를 하지 않는 쪽으로 발전했다. = 데이터베이스가 병목이 될 위험..



## 대용량 시스템이란?

- 고가용성 : 언제든 서비스를 이용할 수 있어야 한다.
- 확장성 : 시스템이 비대해짐에 따라 증가하는 데이터와 트래픽에 대응할 수 있어야 한다.
- 관측 가능성 : 문제가 생겻을 때 빠르게 인지할 수 있어야하고 문제의 범위를 최소화 할 수 있어야 한다.



## MySQL Architecture

> 서버[MySQL Connector] -> SQL query -> MySQL 엔진[query parser -> 전처리기 -> 옵티마이저 -> 쿼리 실행기] -> 스토리지 엔진 -> 운영체제 -> 디스크

### MySQL Engine

- **쿼리파서**
  - SQL을 파싱하여 Syntax Tree를 만듦
  - 이 과정에서 문법 오류 검사가 이루어진다.
- **전처리기**
  - 쿼리파서에 만든 Tree를 바탕으로 전처리 시작
  - 테이블이나 컬럼 존재 여부, 접근권한 등 Semantic 오류 검사

쿼리파서, 전처리기는 컴파일 과정과 매우 유사하지만 SQL은 프로그래밍 언어처럼 컴파일 타임 때 검증 할 수 없어 매번 구문을 평가해야한다.

- **옵티마이저**
  - 쿼리를 처리하기 위한 여러방법을 만들고, 각 방법들의 비용정보와 테이블의 통계정보를 이용해 비용을 산정한다.
  - 테이블 순서, 불필요한 조건 제거, 통계정보를 바탕으로 전략을 결정 (실행 계획 수립)
  - 옵티마이저가 어떤 전략을 결정하냐에 따라 성능이 많이 달라진다.
  - 가끔 성능이 나쁜 판단을 해 개발자가 힌트를 사용해 도움을 줄 수 있다.
- **쿼리실행기**

### 쿼리 캐시

> MySQL 5.0 까지는 쿼리 캐시라는게 존재하였지만 8버전 부터 쿼리 캐시는 삭제 되었다. 이유는 캐싱을 통한 이점보다 데이터 정합성 문제와 더불어 DB Lock 등의 위험성이 더 컸기 때문.

##### 쿼리캐시가 주는 인사이트

- 소프트 파싱 : SQL, 실행계획을 캐시에서 찾아 옵티마이저 과정을 생략하고 실행 단계로 넘어감
- 하드 파싱 : SQL, 실행계획을 캐시에서 찾지못해 옵티마이저 과정을 거치고 나서 실행단계로 넘어감

### 스토리지 엔진

- 디스크에서 데이터를 가져오거나 저장하는 역할
- MySQL 스토리지 엔진은 플러그인 형태로 Handler API만 맞춘다면 직접 구현해서 사용할 수 있다.
- InnoDB, MyIsam 등 여러개의 스토리지 엔진이 존재
- 8.0 버전부터는 InnoDB 엔진이 디폴트

## 정규화와 비정규화

### 정규화

> 관계형 데이터베이스 설계에서 중복을 최소화하게 데이터를 구조화하는 프로세스
